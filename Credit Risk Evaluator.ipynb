{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "\n",
    "# drop loan status column\n",
    "drop_train = train_df.drop('loan_status', axis  = 1)\n",
    "drop_test = test_df.drop('loan_status', axis  = 1)\n",
    "target_feature_train = train_df['loan_status']\n",
    "target_feature_test = test_df['loan_status']\n",
    "\n",
    "# create one-hot encoding of data frames\n",
    "train_dum = pd.get_dummies(drop_train)\n",
    "test_dum = pd.get_dummies(drop_test)\n",
    "\n",
    "train_labels = LabelEncoder().fit_transform(target_feature_train)\n",
    "test_labels = LabelEncoder().fit_transform(target_feature_test)\n",
    "\n",
    "\n",
    "\n",
    "# check number of columns and add missing one to test data\n",
    "\n",
    "for col in train_dum.columns:\n",
    "    if col not in test_dum.columns:\n",
    "        missing_col = col\n",
    "print(\"Missing Feature is : \" + missing_col)\n",
    "\n",
    "# put missing feature into test set and in the same index as found in training set\n",
    "column_num_missing_feature  = list(train_dum.columns).index(missing_col)\n",
    "init_missing_feature = [0 for x in range(test_dum.shape[0])]\n",
    "test_dum.insert(column_num_missing_feature, missing_col, init_missing_feature)\n",
    "\n",
    "test_dum.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Missing Feature is : debt_settlement_flag_Y\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  index  loan_amnt  int_rate  installment  annual_inc    dti  \\\n",
       "0       67991  67991    40000.0    0.0819       814.70    140000.0  19.75   \n",
       "1       25429  25429     6000.0    0.1524       208.70     55000.0  11.52   \n",
       "2       38496  38496     3600.0    0.1695       128.27     42000.0   6.74   \n",
       "3       19667  19667    20000.0    0.1524       478.33    100000.0  12.13   \n",
       "4       37505  37505     3600.0    0.1240       120.27     50000.0  16.08   \n",
       "\n",
       "   delinq_2yrs  inq_last_6mths  open_acc  ...  verification_status_Verified  \\\n",
       "0          0.0             1.0      18.0  ...                             0   \n",
       "1          2.0             0.0       8.0  ...                             0   \n",
       "2          0.0             0.0       6.0  ...                             0   \n",
       "3          0.0             2.0       7.0  ...                             0   \n",
       "4          0.0             3.0       6.0  ...                             0   \n",
       "\n",
       "   pymnt_plan_n  initial_list_status_f  initial_list_status_w  \\\n",
       "0             1                      0                      1   \n",
       "1             1                      0                      1   \n",
       "2             1                      0                      1   \n",
       "3             1                      0                      1   \n",
       "4             1                      0                      1   \n",
       "\n",
       "   application_type_Individual  application_type_Joint App  hardship_flag_N  \\\n",
       "0                            1                           0                1   \n",
       "1                            1                           0                1   \n",
       "2                            1                           0                1   \n",
       "3                            1                           0                1   \n",
       "4                            1                           0                1   \n",
       "\n",
       "   hardship_flag_Y  debt_settlement_flag_N  debt_settlement_flag_Y  \n",
       "0                0                       1                       0  \n",
       "1                0                       1                       0  \n",
       "2                0                       1                       0  \n",
       "3                0                       1                       0  \n",
       "4                0                       1                       0  \n",
       "\n",
       "[5 rows x 94 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>verification_status_Verified</th>\n",
       "      <th>pymnt_plan_n</th>\n",
       "      <th>initial_list_status_f</th>\n",
       "      <th>initial_list_status_w</th>\n",
       "      <th>application_type_Individual</th>\n",
       "      <th>application_type_Joint App</th>\n",
       "      <th>hardship_flag_N</th>\n",
       "      <th>hardship_flag_Y</th>\n",
       "      <th>debt_settlement_flag_N</th>\n",
       "      <th>debt_settlement_flag_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67991</td>\n",
       "      <td>67991</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>814.70</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>19.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25429</td>\n",
       "      <td>25429</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>208.70</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>11.52</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38496</td>\n",
       "      <td>38496</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>128.27</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>6.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19667</td>\n",
       "      <td>19667</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.1524</td>\n",
       "      <td>478.33</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>12.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37505</td>\n",
       "      <td>37505</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>120.27</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>16.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction\n",
    "Logistic regression will be the better model as we have either low risk or high risk loans. Since the classification of interest is strictly binary, logistic regression seems like a much better choice. Logistic regression is also based on explantatory and response variables in an explicit mathematical model. In our case the response variable is loan risk and the explanatory variables are the features found in our data sets. This follows a more tailored approach, therefore will likely perform better. A random forest classifier on the other hand accounts for many classifications and might create unnesscary noise within our classification goal. Upon doing some extra reading, random forest do not fare well in situations with a very high amount of features and may run the risk of overfitting. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "Cs = [1.0,3.0,5.0,7.0,9.0]\n",
    "maxs = [100,750,1000,10000,15000]\n",
    "params = [[Cs[i],maxs[i]] for i in range(len(maxs))]\n",
    "\n",
    "i = 1\n",
    "trains = []\n",
    "tests = []\n",
    "for c in Cs:\n",
    "    for mx in maxs:\n",
    "        LR = LogisticRegression(C=c, class_weight=None, dual=False, fit_intercept=True,\n",
    "                    intercept_scaling=1, l1_ratio=None, max_iter=mx,\n",
    "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                    warm_start=False)\n",
    "        LR.fit(train_dum,train_labels)\n",
    "        print(\"_______________________\")\n",
    "        print(\"iteration \" + str(i))\n",
    "        print(f\"training score : {LR.score(train_dum,train_labels)}\")\n",
    "        print(f\"testing score : {LR.score(test_dum,test_labels)}|reguralization: {c} , max iterations{mx}\")\n",
    "        trains.append(LR.score(train_dum,train_labels))\n",
    "        tests.append(LR.score(test_dum,test_labels))\n",
    "        i = i+1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 1\n",
      "training score : 0.648440065681445\n",
      "testing score : 0.5253083794130158|reguralization: 1.0 , max iterations100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 2\n",
      "training score : 0.6856321839080459\n",
      "testing score : 0.5655040408336878|reguralization: 1.0 , max iterations750\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 3\n",
      "training score : 0.6811986863711001\n",
      "testing score : 0.5542322415993194|reguralization: 1.0 , max iterations1000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 4\n",
      "training score : 0.702216748768473\n",
      "testing score : 0.5642279880901744|reguralization: 1.0 , max iterations10000\n",
      "_______________________\n",
      "iteration 5\n",
      "training score : 0.7016420361247947\n",
      "testing score : 0.5621012335176521|reguralization: 1.0 , max iterations15000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 6\n",
      "training score : 0.648440065681445\n",
      "testing score : 0.5248830284985113|reguralization: 3.0 , max iterations100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 7\n",
      "training score : 0.6852216748768473\n",
      "testing score : 0.5623139089749043|reguralization: 3.0 , max iterations750\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 8\n",
      "training score : 0.6785714285714286\n",
      "testing score : 0.5535942152275627|reguralization: 3.0 , max iterations1000\n",
      "_______________________\n",
      "iteration 9\n",
      "training score : 0.6989326765188835\n",
      "testing score : 0.56571671629094|reguralization: 3.0 , max iterations10000\n",
      "_______________________\n",
      "iteration 10\n",
      "training score : 0.6989326765188835\n",
      "testing score : 0.56571671629094|reguralization: 3.0 , max iterations15000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 11\n",
      "training score : 0.6483579638752053\n",
      "testing score : 0.5248830284985113|reguralization: 5.0 , max iterations100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 12\n",
      "training score : 0.6827586206896552\n",
      "testing score : 0.5563589961718418|reguralization: 5.0 , max iterations750\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 13\n",
      "training score : 0.6807060755336617\n",
      "testing score : 0.5544449170565716|reguralization: 5.0 , max iterations1000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 14\n",
      "training score : 0.7000821018062398\n",
      "testing score : 0.5676307954062101|reguralization: 5.0 , max iterations10000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 15\n",
      "training score : 0.7044334975369458\n",
      "testing score : 0.5716716290940026|reguralization: 5.0 , max iterations15000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 16\n",
      "training score : 0.6483579638752053\n",
      "testing score : 0.5248830284985113|reguralization: 7.0 , max iterations100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 17\n",
      "training score : 0.6885878489326765\n",
      "testing score : 0.5716716290940026|reguralization: 7.0 , max iterations750\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 18\n",
      "training score : 0.7027914614121511\n",
      "testing score : 0.5825180774138664|reguralization: 7.0 , max iterations1000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 19\n",
      "training score : 0.7002463054187192\n",
      "testing score : 0.5669927690344534|reguralization: 7.0 , max iterations10000\n",
      "_______________________\n",
      "iteration 20\n",
      "training score : 0.7006568144499179\n",
      "testing score : 0.5661420672054445|reguralization: 7.0 , max iterations15000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 21\n",
      "training score : 0.6483579638752053\n",
      "testing score : 0.5248830284985113|reguralization: 9.0 , max iterations100\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 22\n",
      "training score : 0.6795566502463054\n",
      "testing score : 0.5542322415993194|reguralization: 9.0 , max iterations750\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration 23\n",
      "training score : 0.6786535303776683\n",
      "testing score : 0.5523181624840493|reguralization: 9.0 , max iterations1000\n",
      "_______________________\n",
      "iteration 24\n",
      "training score : 0.6999178981937603\n",
      "testing score : 0.5712462781794981|reguralization: 9.0 , max iterations10000\n",
      "_______________________\n",
      "iteration 25\n",
      "training score : 0.6999178981937603\n",
      "testing score : 0.5712462781794981|reguralization: 9.0 , max iterations15000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "x_vals = [x for x in range(len(trains))]\n",
    "plt.plot(x_vals,trains)\n",
    "plt.plot(x_vals,tests)\n",
    "print(\"Training Data Max Score and Iteration Number: \")\n",
    "print(max(trains),trains.index(max(trains))+1) \n",
    "print(\"Testing Data Max Score and Iteration Number: \")\n",
    "print(max(tests),tests.index(max(tests))+1) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data Max Score and Iteration Number: \n",
      "0.7044334975369458 15\n",
      "Testing Data Max Score and Iteration Number: \n",
      "0.5825180774138664 18\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "num_est = [x for x in range(1,20)]\n",
    "criteria = [\"gini\",\"entropy\"]\n",
    "\n",
    "j = 1\n",
    "trains_rf = []\n",
    "tests_rf = []\n",
    "for n in num_est:\n",
    "    for c in criteria:\n",
    "        RF = RandomForestClassifier(n_estimators = n, criterion = c)\n",
    "        RF.fit(train_dum,train_labels)\n",
    "        print(\"-------------------\")\n",
    "        print(f\"iteration number: {j}\")\n",
    "        print(f\"training score : {RF.score(train_dum,train_labels)}\")\n",
    "        print(f\"testing score : {RF.score(test_dum,test_labels)}\")\n",
    "        print(f\"number of estimators: {n}, criteria: {c} \")\n",
    "        trains_rf.append(RF.score(train_dum,train_labels))\n",
    "        tests_rf.append(RF.score(test_dum,test_labels))\n",
    "        j = j+1 "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------\n",
      "iteration number: 1\n",
      "training score : 0.8813628899835796\n",
      "testing score : 0.5610378562313909\n",
      "number of estimators: 1, criteria: gini \n",
      "-------------------\n",
      "iteration number: 2\n",
      "training score : 0.8789819376026272\n",
      "testing score : 0.5961293066780093\n",
      "number of estimators: 1, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 3\n",
      "training score : 0.8744663382594418\n",
      "testing score : 0.5472139515099957\n",
      "number of estimators: 2, criteria: gini \n",
      "-------------------\n",
      "iteration number: 4\n",
      "training score : 0.8871921182266009\n",
      "testing score : 0.6233517652062952\n",
      "number of estimators: 2, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 5\n",
      "training score : 0.9464696223316913\n",
      "testing score : 0.5663547426626967\n",
      "number of estimators: 3, criteria: gini \n",
      "-------------------\n",
      "iteration number: 6\n",
      "training score : 0.948768472906404\n",
      "testing score : 0.5903870693321991\n",
      "number of estimators: 3, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 7\n",
      "training score : 0.948768472906404\n",
      "testing score : 0.5997447894512973\n",
      "number of estimators: 4, criteria: gini \n",
      "-------------------\n",
      "iteration number: 8\n",
      "training score : 0.9471264367816092\n",
      "testing score : 0.5421097405359422\n",
      "number of estimators: 4, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 9\n",
      "training score : 0.9705254515599343\n",
      "testing score : 0.622288387920034\n",
      "number of estimators: 5, criteria: gini \n",
      "-------------------\n",
      "iteration number: 10\n",
      "training score : 0.9741379310344828\n",
      "testing score : 0.6171841769459804\n",
      "number of estimators: 5, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 11\n",
      "training score : 0.970935960591133\n",
      "testing score : 0.635048915355168\n",
      "number of estimators: 6, criteria: gini \n",
      "-------------------\n",
      "iteration number: 12\n",
      "training score : 0.9726600985221675\n",
      "testing score : 0.5314759676733305\n",
      "number of estimators: 6, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 13\n",
      "training score : 0.985303776683087\n",
      "testing score : 0.6495108464483199\n",
      "number of estimators: 7, criteria: gini \n",
      "-------------------\n",
      "iteration number: 14\n",
      "training score : 0.9814449917898194\n",
      "testing score : 0.6405784772437261\n",
      "number of estimators: 7, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 15\n",
      "training score : 0.985303776683087\n",
      "testing score : 0.5618885580603998\n",
      "number of estimators: 8, criteria: gini \n",
      "-------------------\n",
      "iteration number: 16\n",
      "training score : 0.9811986863711002\n",
      "testing score : 0.6263292216078264\n",
      "number of estimators: 8, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 17\n",
      "training score : 0.988423645320197\n",
      "testing score : 0.6524883028498512\n",
      "number of estimators: 9, criteria: gini \n",
      "-------------------\n",
      "iteration number: 18\n",
      "training score : 0.9898193760262726\n",
      "testing score : 0.6050616758826032\n",
      "number of estimators: 9, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 19\n",
      "training score : 0.9891625615763546\n",
      "testing score : 0.5754997873245428\n",
      "number of estimators: 10, criteria: gini \n",
      "-------------------\n",
      "iteration number: 20\n",
      "training score : 0.9894088669950739\n",
      "testing score : 0.6095278604849\n",
      "number of estimators: 10, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 21\n",
      "training score : 0.9929392446633826\n",
      "testing score : 0.5754997873245428\n",
      "number of estimators: 11, criteria: gini \n",
      "-------------------\n",
      "iteration number: 22\n",
      "training score : 0.9939244663382595\n",
      "testing score : 0.6027222458528286\n",
      "number of estimators: 11, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 23\n",
      "training score : 0.9933497536945812\n",
      "testing score : 0.6063377286261166\n",
      "number of estimators: 12, criteria: gini \n",
      "-------------------\n",
      "iteration number: 24\n",
      "training score : 0.9922824302134647\n",
      "testing score : 0.6252658443215653\n",
      "number of estimators: 12, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 25\n",
      "training score : 0.9955665024630542\n",
      "testing score : 0.6031475967673331\n",
      "number of estimators: 13, criteria: gini \n",
      "-------------------\n",
      "iteration number: 26\n",
      "training score : 0.9953201970443349\n",
      "testing score : 0.5961293066780093\n",
      "number of estimators: 13, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 27\n",
      "training score : 0.9960591133004926\n",
      "testing score : 0.6167588260314759\n",
      "number of estimators: 14, criteria: gini \n",
      "-------------------\n",
      "iteration number: 28\n",
      "training score : 0.994991789819376\n",
      "testing score : 0.5867715865589112\n",
      "number of estimators: 14, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 29\n",
      "training score : 0.9967980295566502\n",
      "testing score : 0.6152700978307103\n",
      "number of estimators: 15, criteria: gini \n",
      "-------------------\n",
      "iteration number: 30\n",
      "training score : 0.9972906403940887\n",
      "testing score : 0.6684389621437686\n",
      "number of estimators: 15, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 31\n",
      "training score : 0.9969622331691297\n",
      "testing score : 0.6578051892811569\n",
      "number of estimators: 16, criteria: gini \n",
      "-------------------\n",
      "iteration number: 32\n",
      "training score : 0.9969622331691297\n",
      "testing score : 0.6214376860910251\n",
      "number of estimators: 16, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 33\n",
      "training score : 0.9972906403940887\n",
      "testing score : 0.5631646108039132\n",
      "number of estimators: 17, criteria: gini \n",
      "-------------------\n",
      "iteration number: 34\n",
      "training score : 0.9977832512315271\n",
      "testing score : 0.6767333049766057\n",
      "number of estimators: 17, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 35\n",
      "training score : 0.9974548440065681\n",
      "testing score : 0.6618460229689493\n",
      "number of estimators: 18, criteria: gini \n",
      "-------------------\n",
      "iteration number: 36\n",
      "training score : 0.9977011494252873\n",
      "testing score : 0.5852828583581454\n",
      "number of estimators: 18, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 37\n",
      "training score : 0.9986863711001642\n",
      "testing score : 0.5689068481497235\n",
      "number of estimators: 19, criteria: gini \n",
      "-------------------\n",
      "iteration number: 38\n",
      "training score : 0.9982758620689656\n",
      "testing score : 0.5944279030199915\n",
      "number of estimators: 19, criteria: entropy \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "x_vals = [x for x in range(len(trains_rf))]\n",
    "plt.plot(x_vals,trains_rf)\n",
    "plt.plot(x_vals,tests_rf)\n",
    "print(\"Training Data Max Score and Iteration Number: \")\n",
    "print(max(trains_rf),trains_rf.index(max(trains_rf))+1) \n",
    "print(\"Testing Data Max Score and Iteration Number: \")\n",
    "print(max(tests_rf),tests_rf.index(max(tests_rf))+1) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data Max Score and Iteration Number: \n",
      "0.9986863711001642 37\n",
      "Testing Data Max Score and Iteration Number: \n",
      "0.6767333049766057 34\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction for Scaling Results\n",
    "Upon examining the data sets, it is clear that there are many features with large numbers and other features with seemingly small numbers. Scaling will likely create a more balanced data set and result in better performance by the models. This will reduce the possibilty of certain features' magnitudes being favored in model training. Especially since we have a large number features and an extensive data set, we want to eliminate any chance of dealing with larger values that may skew our results. In our situation, this will likely improve our results. \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Scale the data\n",
    "scale_train = StandardScaler().fit(train_dum)\n",
    "X_train_scaled = scale_train.transform(train_dum)\n",
    "X_test_scaled = scale_train.transform(test_dum)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "\n",
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "Cs = [x for x in range(1,51,5)]\n",
    "maxs = [float(x) for x in range(1,25001,2500)]\n",
    "\n",
    "i = 1\n",
    "trains = []\n",
    "tests = []\n",
    "for c in Cs:\n",
    "    for mx in maxs:\n",
    "        LR = LogisticRegression(C=c, class_weight=None, dual=False, fit_intercept=True,\n",
    "                    intercept_scaling=1, l1_ratio=None, max_iter=mx,\n",
    "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                    warm_start=False)\n",
    "        LR.fit(X_train_scaled,train_labels)\n",
    "        print(\"_______________________\")\n",
    "        print(\"iteration\" + str(i))\n",
    "        print(f\"training score : {LR.score(X_train_scaled,train_labels)}\")\n",
    "        print(f\"testing score : {LR.score(X_test_scaled,test_labels)}\")\n",
    "        print(f\"reguralization: {c} , max iterations {mx}\")\n",
    "        trains.append(LR.score(X_train_scaled,train_labels))\n",
    "        tests.append(LR.score(X_test_scaled,test_labels))\n",
    "        i = i+1"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration1\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 1 , max iterations 0.0\n",
      "_______________________\n",
      "iteration2\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration3\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration4\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration5\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration6\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration7\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration8\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration9\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration10\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration11\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration12\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration13\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration14\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration15\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration16\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration17\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration18\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration19\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration20\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration21\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration22\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration23\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration24\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration25\n",
      "training score : 0.7127257799671592\n",
      "testing score : 0.7201190982560612\n",
      "reguralization: 1 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration26\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 3 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration27\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration28\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration29\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration30\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration31\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration32\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration33\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration34\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration35\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration36\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration37\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration38\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration39\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration40\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration41\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration42\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration43\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration44\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration45\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration46\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration47\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration48\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration49\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration50\n",
      "training score : 0.7138752052545156\n",
      "testing score : 0.7141641854529988\n",
      "reguralization: 3 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration51\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 5 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration52\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration53\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration54\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration55\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration56\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration57\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration58\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration59\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration60\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration61\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration62\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration63\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration64\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration65\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration66\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration67\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration68\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration69\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration70\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration71\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration72\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration73\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration74\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration75\n",
      "training score : 0.7140394088669951\n",
      "testing score : 0.7135261590812421\n",
      "reguralization: 5 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration76\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 7 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration77\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration78\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration79\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration80\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration81\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration82\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration83\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration84\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration85\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration86\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration87\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration88\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration89\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration90\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration91\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration92\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration93\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration94\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration95\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration96\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration97\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration98\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration99\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration100\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.7105487026797107\n",
      "reguralization: 7 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration101\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 9 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration102\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration103\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration104\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration105\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration106\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration107\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration108\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration109\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration110\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration111\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration112\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration113\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration114\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration115\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration116\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration117\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration118\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration119\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration120\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration121\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration122\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration123\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration124\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration125\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6926839642705231\n",
      "reguralization: 9 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration126\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 11 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration127\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration128\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration129\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration130\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration131\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration132\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration133\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration134\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration135\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration136\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration137\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration138\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration139\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration140\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration141\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration142\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration143\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration144\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration145\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration146\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration147\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration148\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration149\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration150\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.688855806039983\n",
      "reguralization: 11 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration151\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 13 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration152\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration153\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration154\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration155\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration156\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration157\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration158\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration159\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration160\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration161\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration162\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration163\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration164\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration165\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration166\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration167\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration168\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration169\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration170\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration171\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration172\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration173\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration174\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration175\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6843896214376861\n",
      "reguralization: 13 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration176\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 15 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration177\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration178\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration179\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration180\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration181\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration182\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration183\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration184\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration185\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration186\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration187\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration188\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration189\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration190\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration191\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration192\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration193\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration194\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration195\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration196\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration197\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration198\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration199\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration200\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6867290514674607\n",
      "reguralization: 15 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration201\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 17 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration202\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration203\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration204\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration205\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration206\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration207\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration208\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration209\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration210\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration211\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration212\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration213\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration214\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration215\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration216\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration217\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration218\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration219\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration220\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration221\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration222\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration223\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration224\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration225\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.688005104210974\n",
      "reguralization: 17 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration226\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 19 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration227\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration228\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration229\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration230\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration231\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration232\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration233\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration234\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration235\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration236\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration237\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration238\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration239\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration240\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration241\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration242\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration243\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration244\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration245\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration246\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration247\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration248\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration249\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration250\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.663334751169715\n",
      "reguralization: 19 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration251\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 21 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration252\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration253\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration254\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration255\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration256\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration257\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration258\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration259\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration260\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration261\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration262\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration263\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration264\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration265\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration266\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration267\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration268\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration269\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration270\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration271\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration272\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration273\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration274\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration275\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.676095278604849\n",
      "reguralization: 21 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration276\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 23 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration277\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration278\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration279\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration280\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration281\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration282\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration283\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration284\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration285\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration286\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration287\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration288\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration289\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration290\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration291\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration292\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration293\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration294\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration295\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration296\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration297\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration298\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration299\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration300\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6584432156529136\n",
      "reguralization: 23 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration301\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 25 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration302\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration303\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration304\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration305\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration306\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration307\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration308\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration309\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration310\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration311\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration312\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration313\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration314\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration315\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration316\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration317\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration318\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration319\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration320\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration321\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration322\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration323\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration324\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration325\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6618460229689493\n",
      "reguralization: 25 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration326\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 27 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration327\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration328\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration329\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration330\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration331\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration332\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration333\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration334\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration335\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration336\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration337\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration338\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration339\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration340\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration341\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration342\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration343\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration344\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration345\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration346\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration347\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration348\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration349\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration350\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6484474691620588\n",
      "reguralization: 27 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration351\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 29 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration352\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration353\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration354\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration355\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration356\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration357\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration358\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration359\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration360\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration361\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration362\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration363\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration364\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration365\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration366\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration367\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration368\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration369\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration370\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration371\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration372\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration373\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration374\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration375\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.709910676307954\n",
      "reguralization: 29 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration376\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 31 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration377\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration378\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration379\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration380\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration381\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration382\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration383\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration384\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration385\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration386\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration387\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration388\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration389\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration390\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration391\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration392\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration393\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration394\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration395\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration396\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration397\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration398\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration399\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration400\n",
      "training score : 0.7137931034482758\n",
      "testing score : 0.6333475116971502\n",
      "reguralization: 31 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration401\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 33 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration402\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration403\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration404\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration405\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration406\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration407\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration408\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration409\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration410\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration411\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration412\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration413\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration414\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration415\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration416\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration417\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration418\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration419\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration420\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration421\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration422\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration423\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration424\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration425\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6339855380689069\n",
      "reguralization: 33 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration426\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 35 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration427\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration428\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration429\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration430\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration431\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration432\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration433\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration434\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration435\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration436\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration437\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration438\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration439\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration440\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration441\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration442\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration443\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration444\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration445\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration446\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration447\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration448\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration449\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration450\n",
      "training score : 0.7134646962233169\n",
      "testing score : 0.6550404083368779\n",
      "reguralization: 35 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration451\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 37 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration452\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration453\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration454\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration455\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration456\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration457\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration458\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration459\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration460\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration461\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration462\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration463\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration464\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration465\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration466\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration467\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration468\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration469\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration470\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration471\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration472\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration473\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration474\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration475\n",
      "training score : 0.7133004926108374\n",
      "testing score : 0.6461080391322841\n",
      "reguralization: 37 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration476\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 39 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration477\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration478\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration479\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration480\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration481\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration482\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration483\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration484\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration485\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration486\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration487\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration488\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration489\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration490\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration491\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration492\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration493\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration494\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration495\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration496\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration497\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration498\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration499\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration500\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6348362398979158\n",
      "reguralization: 39 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration501\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 41 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration502\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration503\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration504\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration505\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration506\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration507\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration508\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration509\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration510\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration511\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration512\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration513\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration514\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration515\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration516\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration517\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration518\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration519\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration520\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration521\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration522\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration523\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration524\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration525\n",
      "training score : 0.7136288998357964\n",
      "testing score : 0.6086771586558911\n",
      "reguralization: 41 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration526\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 43 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration527\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration528\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration529\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration530\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration531\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration532\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration533\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration534\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration535\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration536\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration537\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration538\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration539\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration540\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration541\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration542\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration543\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration544\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration545\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration546\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration547\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration548\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration549\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration550\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6303700552956188\n",
      "reguralization: 43 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration551\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 45 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration552\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration553\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration554\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration555\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration556\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration557\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration558\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration559\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration560\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration561\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration562\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration563\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration564\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration565\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration566\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration567\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration568\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration569\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration570\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration571\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration572\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration573\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration574\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration575\n",
      "training score : 0.7135467980295567\n",
      "testing score : 0.6252658443215653\n",
      "reguralization: 45 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration576\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 47 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration577\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration578\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration579\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration580\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration581\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration582\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration583\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration584\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration585\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration586\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration587\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration588\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration589\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration590\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration591\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration592\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration593\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration594\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration595\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration596\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration597\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration598\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration599\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration600\n",
      "training score : 0.7139573070607553\n",
      "testing score : 0.6088898341131433\n",
      "reguralization: 47 , max iterations 24000.0\n",
      "_______________________\n",
      "iteration601\n",
      "training score : 0.6425287356321839\n",
      "testing score : 0.5669927690344534\n",
      "reguralization: 49 , max iterations 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________________\n",
      "iteration602\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 1000.0\n",
      "_______________________\n",
      "iteration603\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 2000.0\n",
      "_______________________\n",
      "iteration604\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 3000.0\n",
      "_______________________\n",
      "iteration605\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 4000.0\n",
      "_______________________\n",
      "iteration606\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 5000.0\n",
      "_______________________\n",
      "iteration607\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 6000.0\n",
      "_______________________\n",
      "iteration608\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 7000.0\n",
      "_______________________\n",
      "iteration609\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 8000.0\n",
      "_______________________\n",
      "iteration610\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 9000.0\n",
      "_______________________\n",
      "iteration611\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 10000.0\n",
      "_______________________\n",
      "iteration612\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 11000.0\n",
      "_______________________\n",
      "iteration613\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 12000.0\n",
      "_______________________\n",
      "iteration614\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 13000.0\n",
      "_______________________\n",
      "iteration615\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 14000.0\n",
      "_______________________\n",
      "iteration616\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 15000.0\n",
      "_______________________\n",
      "iteration617\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 16000.0\n",
      "_______________________\n",
      "iteration618\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 17000.0\n",
      "_______________________\n",
      "iteration619\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 18000.0\n",
      "_______________________\n",
      "iteration620\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 19000.0\n",
      "_______________________\n",
      "iteration621\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 20000.0\n",
      "_______________________\n",
      "iteration622\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 21000.0\n",
      "_______________________\n",
      "iteration623\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 22000.0\n",
      "_______________________\n",
      "iteration624\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 23000.0\n",
      "_______________________\n",
      "iteration625\n",
      "training score : 0.7133825944170772\n",
      "testing score : 0.6365376435559337\n",
      "reguralization: 49 , max iterations 24000.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "x_vals = [x for x in range(len(trains))]\n",
    "plt.plot(x_vals,trains)\n",
    "plt.plot(x_vals,tests)\n",
    "print(\"Training Data Max Score and Iteration Number: \")\n",
    "print(max(trains),trains.index(max(trains))+1) \n",
    "print(\"Testing Data Max Score and Iteration Number: \")\n",
    "print(max(tests),tests.index(max(tests))+1) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data Max Score and Iteration Number: \n",
      "0.7140394088669951 52\n",
      "Testing Data Max Score and Iteration Number: \n",
      "0.7201190982560612 2\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "Cs = [x for x in range(1,51,5)]\n",
    "maxs = [float(x+250) for x in range(0,25000,2500)]\n",
    "p_grid = {'C':Cs,\"max_iter\":maxs}\n",
    "model = LogisticRegression()\n",
    "grid_clf = GridSearchCV(model, p_grid, verbose=3)\n",
    "# grid search just does a nested for loop type structure as seen in my implementations above\n",
    "random_clf = RandomizedSearchCV(model,p_grid,n_iter=100,random_state=1, verbose=3)\n",
    "random_clf.fit(X_train_scaled,train_labels)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV] max_iter=250.0, C=1 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=1, score=0.486, total=   0.4s\n",
      "[CV] max_iter=250.0, C=1 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=1, score=0.590, total=   0.4s\n",
      "[CV] max_iter=250.0, C=1 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=1, score=0.727, total=   0.4s\n",
      "[CV] max_iter=250.0, C=1 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=250.0, C=1 .............................................\n",
      "[CV] ................. max_iter=250.0, C=1, score=0.710, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=1, score=0.486, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=1, score=0.590, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=1, score=0.727, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=1, score=0.710, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=1 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=1, score=0.486, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=1 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=1, score=0.590, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=1 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=1, score=0.727, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=1 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=1 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=1, score=0.710, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=1, score=0.486, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=1, score=0.590, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=1, score=0.727, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=1, score=0.737, total=   1.8s\n",
      "[CV] max_iter=7750.0, C=1 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=1, score=0.710, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=1, score=0.486, total=   0.4s\n",
      "[CV] max_iter=10250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=1, score=0.590, total=   0.3s\n",
      "[CV] max_iter=10250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=1, score=0.727, total=   0.3s\n",
      "[CV] max_iter=10250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=1, score=0.737, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=1, score=0.710, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=1, score=0.486, total=   0.7s\n",
      "[CV] max_iter=12750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=1, score=0.590, total=   1.4s\n",
      "[CV] max_iter=12750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=1, score=0.727, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=1, score=0.710, total=   0.3s\n",
      "[CV] max_iter=15250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=1, score=0.486, total=   0.3s\n",
      "[CV] max_iter=15250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=1, score=0.590, total=   0.3s\n",
      "[CV] max_iter=15250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=1, score=0.727, total=   0.3s\n",
      "[CV] max_iter=15250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=1, score=0.710, total=   0.3s\n",
      "[CV] max_iter=17750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=1, score=0.486, total=   0.3s\n",
      "[CV] max_iter=17750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=1, score=0.590, total=   0.3s\n",
      "[CV] max_iter=17750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=1, score=0.727, total=   0.3s\n",
      "[CV] max_iter=17750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=1, score=0.710, total=   0.3s\n",
      "[CV] max_iter=20250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=1, score=0.486, total=   0.3s\n",
      "[CV] max_iter=20250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=1, score=0.590, total=   0.3s\n",
      "[CV] max_iter=20250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=1, score=0.727, total=   0.3s\n",
      "[CV] max_iter=20250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=1, score=0.710, total=   0.3s\n",
      "[CV] max_iter=22750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=1, score=0.486, total=   0.3s\n",
      "[CV] max_iter=22750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=1, score=0.590, total=   0.3s\n",
      "[CV] max_iter=22750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=1, score=0.727, total=   0.3s\n",
      "[CV] max_iter=22750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=1, score=0.737, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=1 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=1, score=0.710, total=   0.3s\n",
      "[CV] max_iter=250.0, C=6 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=6, score=0.486, total=   0.3s\n",
      "[CV] max_iter=250.0, C=6 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=250.0, C=6 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=6, score=0.727, total=   0.3s\n",
      "[CV] max_iter=250.0, C=6 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=6, score=0.738, total=   0.3s\n",
      "[CV] max_iter=250.0, C=6 .............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................. max_iter=250.0, C=6, score=0.711, total=   0.3s\n",
      "[CV] max_iter=2750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=6, score=0.486, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=6, score=0.739, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=2750.0, C=6, score=0.711, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=6 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=6, score=0.486, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=6 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=6 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=6 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=6, score=0.739, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=6 ............................................\n",
      "[CV] ................ max_iter=5250.0, C=6, score=0.711, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=6, score=0.486, total=   0.5s\n",
      "[CV] max_iter=7750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=6, score=0.739, total=   0.5s\n",
      "[CV] max_iter=7750.0, C=6 ............................................\n",
      "[CV] ................ max_iter=7750.0, C=6, score=0.711, total=   0.4s\n",
      "[CV] max_iter=10250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=6, score=0.486, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=10250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=10250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=6, score=0.739, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=10250.0, C=6, score=0.711, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=6, score=0.486, total=   0.5s\n",
      "[CV] max_iter=12750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=6, score=0.739, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=12750.0, C=6, score=0.711, total=   0.5s\n",
      "[CV] max_iter=15250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=6, score=0.486, total=   0.6s\n",
      "[CV] max_iter=15250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=6, score=0.739, total=   0.6s\n",
      "[CV] max_iter=15250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=15250.0, C=6, score=0.711, total=   0.5s\n",
      "[CV] max_iter=17750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=6, score=0.486, total=   0.6s\n",
      "[CV] max_iter=17750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=6, score=0.727, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=6, score=0.739, total=   0.6s\n",
      "[CV] max_iter=17750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=17750.0, C=6, score=0.711, total=   0.5s\n",
      "[CV] max_iter=20250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=6, score=0.486, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=6, score=0.727, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=6, score=0.739, total=   0.7s\n",
      "[CV] max_iter=20250.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=20250.0, C=6, score=0.711, total=   0.7s\n",
      "[CV] max_iter=22750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=6, score=0.486, total=   0.7s\n",
      "[CV] max_iter=22750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=6, score=0.590, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=6, score=0.727, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=6, score=0.739, total=   0.6s\n",
      "[CV] max_iter=22750.0, C=6 ...........................................\n",
      "[CV] ............... max_iter=22750.0, C=6, score=0.711, total=   0.5s\n",
      "[CV] max_iter=250.0, C=11 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=11, score=0.485, total=   0.4s\n",
      "[CV] max_iter=250.0, C=11 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=11, score=0.589, total=   0.4s\n",
      "[CV] max_iter=250.0, C=11 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=250.0, C=11 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=11, score=0.737, total=   0.4s\n",
      "[CV] max_iter=250.0, C=11 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=11, score=0.709, total=   0.3s\n",
      "[CV] max_iter=2750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=11, score=0.485, total=   0.9s\n",
      "[CV] max_iter=2750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=2750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=5250.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=5250.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=7750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=7750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=7750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=7750.0, C=11 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=10250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=10250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=12750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=12750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=12750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=15250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=15250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=15250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=11, score=0.738, total=   0.6s\n",
      "[CV] max_iter=15250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=11, score=0.710, total=   0.5s\n",
      "[CV] max_iter=17750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=11, score=0.485, total=   0.7s\n",
      "[CV] max_iter=17750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=11, score=0.589, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=17750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=20250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=20250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=20250.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=22750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=11, score=0.485, total=   0.8s\n",
      "[CV] max_iter=22750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=11, score=0.589, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=11, score=0.727, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=11, score=0.738, total=   0.7s\n",
      "[CV] max_iter=22750.0, C=11 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=11, score=0.710, total=   0.6s\n",
      "[CV] max_iter=250.0, C=16 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=16, score=0.486, total=   0.4s\n",
      "[CV] max_iter=250.0, C=16 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=16, score=0.589, total=   0.4s\n",
      "[CV] max_iter=250.0, C=16 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=16, score=0.727, total=   0.5s\n",
      "[CV] max_iter=250.0, C=16 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=16, score=0.737, total=   0.4s\n",
      "[CV] max_iter=250.0, C=16 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=16, score=0.709, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=16, score=0.486, total=   1.2s\n",
      "[CV] max_iter=2750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=16, score=0.589, total=   1.2s\n",
      "[CV] max_iter=2750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=16, score=0.728, total=   0.6s\n",
      "[CV] max_iter=2750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=16, score=0.738, total=   0.8s\n",
      "[CV] max_iter=2750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=16, score=0.710, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=16, score=0.486, total=   2.1s\n",
      "[CV] max_iter=5250.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=16, score=0.589, total=   1.2s\n",
      "[CV] max_iter=5250.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=16, score=0.728, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=16, score=0.738, total=   1.5s\n",
      "[CV] max_iter=5250.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=16, score=0.710, total=   1.5s\n",
      "[CV] max_iter=7750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=16, score=0.486, total=   1.9s\n",
      "[CV] max_iter=7750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=16, score=0.589, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=16, score=0.728, total=   0.9s\n",
      "[CV] max_iter=7750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=16, score=0.738, total=   1.4s\n",
      "[CV] max_iter=7750.0, C=16 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=16, score=0.710, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=16, score=0.486, total=   1.0s\n",
      "[CV] max_iter=10250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=16, score=0.589, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=16, score=0.728, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=16, score=0.738, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=16, score=0.710, total=   1.1s\n",
      "[CV] max_iter=12750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=16, score=0.486, total=   1.0s\n",
      "[CV] max_iter=12750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=16, score=0.589, total=   0.7s\n",
      "[CV] max_iter=12750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=16, score=0.728, total=   1.0s\n",
      "[CV] max_iter=12750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=16, score=0.738, total=   1.0s\n",
      "[CV] max_iter=12750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=16, score=0.710, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=16, score=0.486, total=   1.2s\n",
      "[CV] max_iter=15250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=16, score=0.589, total=   1.1s\n",
      "[CV] max_iter=15250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=16, score=0.728, total=   0.8s\n",
      "[CV] max_iter=15250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=16, score=0.738, total=   2.7s\n",
      "[CV] max_iter=15250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=16, score=0.710, total=   1.2s\n",
      "[CV] max_iter=17750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=16, score=0.486, total=   2.2s\n",
      "[CV] max_iter=17750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=16, score=0.589, total=   0.7s\n",
      "[CV] max_iter=17750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=16, score=0.728, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=16, score=0.738, total=   1.0s\n",
      "[CV] max_iter=17750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=16, score=0.710, total=   2.1s\n",
      "[CV] max_iter=20250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=16, score=0.486, total=   2.8s\n",
      "[CV] max_iter=20250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=16, score=0.589, total=   1.4s\n",
      "[CV] max_iter=20250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=16, score=0.728, total=   0.5s\n",
      "[CV] max_iter=20250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=16, score=0.738, total=   0.9s\n",
      "[CV] max_iter=20250.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=16, score=0.710, total=   1.0s\n",
      "[CV] max_iter=22750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=16, score=0.486, total=   1.1s\n",
      "[CV] max_iter=22750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=16, score=0.589, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=16, score=0.728, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=16, score=0.738, total=   0.9s\n",
      "[CV] max_iter=22750.0, C=16 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=16, score=0.710, total=   1.1s\n",
      "[CV] max_iter=250.0, C=21 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=21, score=0.486, total=   0.5s\n",
      "[CV] max_iter=250.0, C=21 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=21, score=0.590, total=   0.5s\n",
      "[CV] max_iter=250.0, C=21 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=21, score=0.727, total=   0.5s\n",
      "[CV] max_iter=250.0, C=21 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=21, score=0.736, total=   0.5s\n",
      "[CV] max_iter=250.0, C=21 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=21, score=0.710, total=   0.6s\n",
      "[CV] max_iter=2750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=21, score=0.486, total=   1.1s\n",
      "[CV] max_iter=2750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=21, score=0.589, total=   0.7s\n",
      "[CV] max_iter=2750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=21, score=0.727, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=21, score=0.736, total=   1.1s\n",
      "[CV] max_iter=2750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=21, score=0.710, total=   0.8s\n",
      "[CV] max_iter=5250.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=21, score=0.486, total=   1.1s\n",
      "[CV] max_iter=5250.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=21, score=0.589, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=21, score=0.727, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=21, score=0.736, total=   1.1s\n",
      "[CV] max_iter=5250.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=21, score=0.710, total=   0.8s\n",
      "[CV] max_iter=7750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=21, score=0.486, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=21, score=0.589, total=   0.7s\n",
      "[CV] max_iter=7750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=21, score=0.727, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=21, score=0.736, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=21 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=21, score=0.710, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=21, score=0.486, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=21, score=0.589, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=21, score=0.727, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=21, score=0.736, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=21, score=0.710, total=   0.8s\n",
      "[CV] max_iter=12750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=21, score=0.486, total=   1.1s\n",
      "[CV] max_iter=12750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=21, score=0.589, total=   0.7s\n",
      "[CV] max_iter=12750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=21, score=0.727, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=21, score=0.736, total=   1.2s\n",
      "[CV] max_iter=12750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=21, score=0.710, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=21, score=0.486, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=21, score=0.589, total=   0.7s\n",
      "[CV] max_iter=15250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=21, score=0.727, total=   0.5s\n",
      "[CV] max_iter=15250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=21, score=0.736, total=   3.1s\n",
      "[CV] max_iter=15250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=21, score=0.710, total=   2.6s\n",
      "[CV] max_iter=17750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=21, score=0.486, total=   1.3s\n",
      "[CV] max_iter=17750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=21, score=0.589, total=   0.6s\n",
      "[CV] max_iter=17750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=21, score=0.727, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=21, score=0.736, total=   0.9s\n",
      "[CV] max_iter=17750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=21, score=0.710, total=   0.8s\n",
      "[CV] max_iter=20250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=21, score=0.486, total=   1.0s\n",
      "[CV] max_iter=20250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=21, score=0.589, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=21, score=0.727, total=   0.5s\n",
      "[CV] max_iter=20250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=21, score=0.736, total=   1.0s\n",
      "[CV] max_iter=20250.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=21, score=0.710, total=   0.7s\n",
      "[CV] max_iter=22750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=21, score=0.486, total=   0.9s\n",
      "[CV] max_iter=22750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=21, score=0.589, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=21, score=0.727, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=21, score=0.736, total=   1.0s\n",
      "[CV] max_iter=22750.0, C=21 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=21, score=0.710, total=   0.8s\n",
      "[CV] max_iter=250.0, C=26 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=26, score=0.486, total=   0.4s\n",
      "[CV] max_iter=250.0, C=26 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=26, score=0.590, total=   0.4s\n",
      "[CV] max_iter=250.0, C=26 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=26, score=0.727, total=   0.4s\n",
      "[CV] max_iter=250.0, C=26 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=26, score=0.736, total=   0.4s\n",
      "[CV] max_iter=250.0, C=26 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=26, score=0.709, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=26, score=0.486, total=   1.0s\n",
      "[CV] max_iter=2750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=26, score=0.589, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=26, score=0.728, total=   0.7s\n",
      "[CV] max_iter=2750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=26, score=0.736, total=   1.3s\n",
      "[CV] max_iter=2750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=26, score=0.710, total=   1.1s\n",
      "[CV] max_iter=5250.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=26, score=0.486, total=   1.5s\n",
      "[CV] max_iter=5250.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=26, score=0.589, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=26, score=0.728, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=26, score=0.736, total=   1.2s\n",
      "[CV] max_iter=5250.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=26, score=0.710, total=   0.8s\n",
      "[CV] max_iter=7750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=26, score=0.486, total=   1.0s\n",
      "[CV] max_iter=7750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=26, score=0.589, total=   0.5s\n",
      "[CV] max_iter=7750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=26, score=0.728, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=26, score=0.736, total=   1.2s\n",
      "[CV] max_iter=7750.0, C=26 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=26, score=0.710, total=   0.9s\n",
      "[CV] max_iter=10250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=26, score=0.486, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=26, score=0.589, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=26, score=0.728, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=26, score=0.736, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=26, score=0.710, total=   0.9s\n",
      "[CV] max_iter=12750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=26, score=0.486, total=   1.5s\n",
      "[CV] max_iter=12750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=26, score=0.589, total=   0.5s\n",
      "[CV] max_iter=12750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=26, score=0.728, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=26, score=0.736, total=   1.4s\n",
      "[CV] max_iter=12750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=26, score=0.710, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=26, score=0.486, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=26, score=0.589, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=26, score=0.728, total=   0.5s\n",
      "[CV] max_iter=15250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=26, score=0.736, total=   1.1s\n",
      "[CV] max_iter=15250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=26, score=0.710, total=   0.8s\n",
      "[CV] max_iter=17750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=26, score=0.486, total=   1.1s\n",
      "[CV] max_iter=17750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=26, score=0.589, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=26, score=0.728, total=   0.5s\n",
      "[CV] max_iter=17750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=26, score=0.736, total=   1.1s\n",
      "[CV] max_iter=17750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=26, score=0.710, total=   0.8s\n",
      "[CV] max_iter=20250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=26, score=0.486, total=   1.0s\n",
      "[CV] max_iter=20250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=26, score=0.589, total=   0.5s\n",
      "[CV] max_iter=20250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=26, score=0.728, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=26, score=0.736, total=   0.9s\n",
      "[CV] max_iter=20250.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=26, score=0.710, total=   0.7s\n",
      "[CV] max_iter=22750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=26, score=0.486, total=   0.8s\n",
      "[CV] max_iter=22750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=26, score=0.589, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=26, score=0.728, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=26, score=0.736, total=   1.0s\n",
      "[CV] max_iter=22750.0, C=26 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=26, score=0.710, total=   0.7s\n",
      "[CV] max_iter=250.0, C=31 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=31, score=0.486, total=   0.4s\n",
      "[CV] max_iter=250.0, C=31 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=31, score=0.590, total=   0.5s\n",
      "[CV] max_iter=250.0, C=31 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=31, score=0.728, total=   0.5s\n",
      "[CV] max_iter=250.0, C=31 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=31, score=0.736, total=   0.6s\n",
      "[CV] max_iter=250.0, C=31 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=31, score=0.709, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=31, score=0.486, total=   1.1s\n",
      "[CV] max_iter=2750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=31, score=0.590, total=   0.8s\n",
      "[CV] max_iter=2750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=31, score=0.728, total=   0.6s\n",
      "[CV] max_iter=2750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=31, score=0.737, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=31, score=0.710, total=   1.6s\n",
      "[CV] max_iter=5250.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=31, score=0.486, total=   1.4s\n",
      "[CV] max_iter=5250.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=31, score=0.590, total=   0.6s\n",
      "[CV] max_iter=5250.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=31, score=0.728, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=31, score=0.737, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=31, score=0.710, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=31, score=0.486, total=   1.2s\n",
      "[CV] max_iter=7750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=31, score=0.590, total=   0.8s\n",
      "[CV] max_iter=7750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=31, score=0.728, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=31, score=0.737, total=   0.5s\n",
      "[CV] max_iter=7750.0, C=31 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=31, score=0.710, total=   1.0s\n",
      "[CV] max_iter=10250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=31, score=0.486, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=31, score=0.590, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=31, score=0.728, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=31, score=0.737, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=31, score=0.710, total=   0.9s\n",
      "[CV] max_iter=12750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=31, score=0.486, total=   1.0s\n",
      "[CV] max_iter=12750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=31, score=0.590, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=31, score=0.728, total=   0.4s\n",
      "[CV] max_iter=12750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=31, score=0.737, total=   0.5s\n",
      "[CV] max_iter=12750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=31, score=0.710, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=31, score=0.486, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=31, score=0.590, total=   0.6s\n",
      "[CV] max_iter=15250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=31, score=0.728, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=31, score=0.737, total=   0.6s\n",
      "[CV] max_iter=15250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=31, score=0.710, total=   1.2s\n",
      "[CV] max_iter=17750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=31, score=0.486, total=   1.2s\n",
      "[CV] max_iter=17750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=31, score=0.590, total=   0.7s\n",
      "[CV] max_iter=17750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=31, score=0.728, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=31, score=0.737, total=   0.5s\n",
      "[CV] max_iter=17750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=31, score=0.710, total=   0.9s\n",
      "[CV] max_iter=20250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=31, score=0.486, total=   1.1s\n",
      "[CV] max_iter=20250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=31, score=0.590, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=31, score=0.728, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=31, score=0.737, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=31, score=0.710, total=   0.8s\n",
      "[CV] max_iter=22750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=31, score=0.486, total=   1.4s\n",
      "[CV] max_iter=22750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=31, score=0.590, total=   0.8s\n",
      "[CV] max_iter=22750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=31, score=0.728, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=31, score=0.737, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=31 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=31, score=0.710, total=   0.9s\n",
      "[CV] max_iter=250.0, C=36 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=36, score=0.486, total=   0.4s\n",
      "[CV] max_iter=250.0, C=36 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=36, score=0.590, total=   0.4s\n",
      "[CV] max_iter=250.0, C=36 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=36, score=0.728, total=   0.4s\n",
      "[CV] max_iter=250.0, C=36 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=36, score=0.736, total=   0.4s\n",
      "[CV] max_iter=250.0, C=36 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=36, score=0.710, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=36, score=0.486, total=   1.3s\n",
      "[CV] max_iter=2750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=36, score=0.589, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=36, score=0.728, total=   0.5s\n",
      "[CV] max_iter=2750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=36, score=0.736, total=   1.0s\n",
      "[CV] max_iter=2750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=36, score=0.710, total=   1.1s\n",
      "[CV] max_iter=5250.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=36, score=0.486, total=   1.0s\n",
      "[CV] max_iter=5250.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=36, score=0.589, total=   0.7s\n",
      "[CV] max_iter=5250.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=36, score=0.728, total=   0.6s\n",
      "[CV] max_iter=5250.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=36, score=0.736, total=   1.2s\n",
      "[CV] max_iter=5250.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=36, score=0.710, total=   1.7s\n",
      "[CV] max_iter=7750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=36, score=0.486, total=   1.3s\n",
      "[CV] max_iter=7750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=36, score=0.589, total=   0.8s\n",
      "[CV] max_iter=7750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=36, score=0.728, total=   1.3s\n",
      "[CV] max_iter=7750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=36, score=0.736, total=   1.6s\n",
      "[CV] max_iter=7750.0, C=36 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=36, score=0.710, total=   1.3s\n",
      "[CV] max_iter=10250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=36, score=0.486, total=   1.2s\n",
      "[CV] max_iter=10250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=36, score=0.589, total=   0.9s\n",
      "[CV] max_iter=10250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=36, score=0.728, total=   0.7s\n",
      "[CV] max_iter=10250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=36, score=0.736, total=   0.9s\n",
      "[CV] max_iter=10250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=36, score=0.710, total=   1.3s\n",
      "[CV] max_iter=12750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=36, score=0.486, total=   1.4s\n",
      "[CV] max_iter=12750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=36, score=0.589, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=36, score=0.728, total=   0.5s\n",
      "[CV] max_iter=12750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=36, score=0.736, total=   1.1s\n",
      "[CV] max_iter=12750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=36, score=0.710, total=   1.4s\n",
      "[CV] max_iter=15250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=36, score=0.486, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=36, score=0.589, total=   1.8s\n",
      "[CV] max_iter=15250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=36, score=0.728, total=   0.7s\n",
      "[CV] max_iter=15250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=36, score=0.736, total=   2.3s\n",
      "[CV] max_iter=15250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=36, score=0.710, total=   2.9s\n",
      "[CV] max_iter=17750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=36, score=0.486, total=   2.0s\n",
      "[CV] max_iter=17750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=36, score=0.589, total=   1.5s\n",
      "[CV] max_iter=17750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=36, score=0.728, total=   1.2s\n",
      "[CV] max_iter=17750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=36, score=0.736, total=   2.4s\n",
      "[CV] max_iter=17750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=36, score=0.710, total=   1.3s\n",
      "[CV] max_iter=20250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=36, score=0.486, total=   1.0s\n",
      "[CV] max_iter=20250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=36, score=0.589, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=36, score=0.728, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=36, score=0.736, total=   0.9s\n",
      "[CV] max_iter=20250.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=36, score=0.710, total=   1.2s\n",
      "[CV] max_iter=22750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=36, score=0.486, total=   1.0s\n",
      "[CV] max_iter=22750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=36, score=0.589, total=   0.6s\n",
      "[CV] max_iter=22750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=36, score=0.728, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=36, score=0.736, total=   0.9s\n",
      "[CV] max_iter=22750.0, C=36 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=36, score=0.710, total=   1.2s\n",
      "[CV] max_iter=250.0, C=41 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=41, score=0.486, total=   0.4s\n",
      "[CV] max_iter=250.0, C=41 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=41, score=0.589, total=   0.5s\n",
      "[CV] max_iter=250.0, C=41 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=41, score=0.728, total=   0.4s\n",
      "[CV] max_iter=250.0, C=41 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=41, score=0.736, total=   0.4s\n",
      "[CV] max_iter=250.0, C=41 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=41, score=0.710, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=41, score=0.486, total=   1.0s\n",
      "[CV] max_iter=2750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=41, score=0.589, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=41, score=0.728, total=   1.0s\n",
      "[CV] max_iter=2750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=41, score=0.737, total=   0.8s\n",
      "[CV] max_iter=2750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=41, score=0.710, total=   0.6s\n",
      "[CV] max_iter=5250.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=41, score=0.486, total=   0.9s\n",
      "[CV] max_iter=5250.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=41, score=0.589, total=   0.5s\n",
      "[CV] max_iter=5250.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=41, score=0.728, total=   1.0s\n",
      "[CV] max_iter=5250.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=41, score=0.737, total=   0.8s\n",
      "[CV] max_iter=5250.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=41, score=0.710, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=41, score=0.486, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=41, score=0.589, total=   0.6s\n",
      "[CV] max_iter=7750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=41, score=0.728, total=   1.5s\n",
      "[CV] max_iter=7750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=41, score=0.737, total=   0.9s\n",
      "[CV] max_iter=7750.0, C=41 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=41, score=0.710, total=   0.6s\n",
      "[CV] max_iter=10250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=41, score=0.486, total=   0.9s\n",
      "[CV] max_iter=10250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=41, score=0.589, total=   0.4s\n",
      "[CV] max_iter=10250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=41, score=0.728, total=   0.9s\n",
      "[CV] max_iter=10250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=41, score=0.737, total=   0.8s\n",
      "[CV] max_iter=10250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=41, score=0.710, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=41, score=0.486, total=   0.9s\n",
      "[CV] max_iter=12750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=41, score=0.589, total=   0.5s\n",
      "[CV] max_iter=12750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=41, score=0.728, total=   1.3s\n",
      "[CV] max_iter=12750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=41, score=0.737, total=   0.8s\n",
      "[CV] max_iter=12750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=41, score=0.710, total=   0.5s\n",
      "[CV] max_iter=15250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=41, score=0.486, total=   0.8s\n",
      "[CV] max_iter=15250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=41, score=0.589, total=   0.4s\n",
      "[CV] max_iter=15250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=41, score=0.728, total=   0.8s\n",
      "[CV] max_iter=15250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=41, score=0.737, total=   0.7s\n",
      "[CV] max_iter=15250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=41, score=0.710, total=   0.5s\n",
      "[CV] max_iter=17750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=41, score=0.486, total=   0.8s\n",
      "[CV] max_iter=17750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=41, score=0.589, total=   0.4s\n",
      "[CV] max_iter=17750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=41, score=0.728, total=   0.8s\n",
      "[CV] max_iter=17750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=41, score=0.737, total=   0.7s\n",
      "[CV] max_iter=17750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=41, score=0.710, total=   0.5s\n",
      "[CV] max_iter=20250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=41, score=0.486, total=   0.8s\n",
      "[CV] max_iter=20250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=41, score=0.589, total=   0.4s\n",
      "[CV] max_iter=20250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=41, score=0.728, total=   0.8s\n",
      "[CV] max_iter=20250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=41, score=0.737, total=   0.7s\n",
      "[CV] max_iter=20250.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=41, score=0.710, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=41, score=0.486, total=   0.8s\n",
      "[CV] max_iter=22750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=41, score=0.589, total=   0.4s\n",
      "[CV] max_iter=22750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=41, score=0.728, total=   0.8s\n",
      "[CV] max_iter=22750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=41, score=0.737, total=   0.7s\n",
      "[CV] max_iter=22750.0, C=41 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=41, score=0.710, total=   0.5s\n",
      "[CV] max_iter=250.0, C=46 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=46, score=0.486, total=   0.3s\n",
      "[CV] max_iter=250.0, C=46 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=46, score=0.592, total=   0.3s\n",
      "[CV] max_iter=250.0, C=46 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=46, score=0.727, total=   0.4s\n",
      "[CV] max_iter=250.0, C=46 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=46, score=0.736, total=   0.4s\n",
      "[CV] max_iter=250.0, C=46 ............................................\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[CV] ................ max_iter=250.0, C=46, score=0.709, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=46, score=0.486, total=   0.8s\n",
      "[CV] max_iter=2750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=46, score=0.589, total=   0.9s\n",
      "[CV] max_iter=2750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=46, score=0.728, total=   0.4s\n",
      "[CV] max_iter=2750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=46, score=0.737, total=   1.0s\n",
      "[CV] max_iter=2750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=2750.0, C=46, score=0.709, total=   0.8s\n",
      "[CV] max_iter=5250.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=46, score=0.486, total=   0.8s\n",
      "[CV] max_iter=5250.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=46, score=0.589, total=   0.9s\n",
      "[CV] max_iter=5250.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=46, score=0.728, total=   0.4s\n",
      "[CV] max_iter=5250.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=46, score=0.737, total=   1.1s\n",
      "[CV] max_iter=5250.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=5250.0, C=46, score=0.709, total=   1.3s\n",
      "[CV] max_iter=7750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=46, score=0.486, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=7750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=46, score=0.728, total=   0.5s\n",
      "[CV] max_iter=7750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=46, score=0.737, total=   1.3s\n",
      "[CV] max_iter=7750.0, C=46 ...........................................\n",
      "[CV] ............... max_iter=7750.0, C=46, score=0.709, total=   0.9s\n",
      "[CV] max_iter=10250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=46, score=0.486, total=   1.0s\n",
      "[CV] max_iter=10250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=46, score=0.728, total=   0.5s\n",
      "[CV] max_iter=10250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=46, score=0.737, total=   1.1s\n",
      "[CV] max_iter=10250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=10250.0, C=46, score=0.709, total=   1.0s\n",
      "[CV] max_iter=12750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=46, score=0.486, total=   1.1s\n",
      "[CV] max_iter=12750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=12750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=46, score=0.728, total=   0.6s\n",
      "[CV] max_iter=12750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=46, score=0.737, total=   1.1s\n",
      "[CV] max_iter=12750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=12750.0, C=46, score=0.709, total=   1.1s\n",
      "[CV] max_iter=15250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=46, score=0.486, total=   1.0s\n",
      "[CV] max_iter=15250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=15250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=46, score=0.728, total=   0.5s\n",
      "[CV] max_iter=15250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=46, score=0.737, total=   1.2s\n",
      "[CV] max_iter=15250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=15250.0, C=46, score=0.709, total=   1.0s\n",
      "[CV] max_iter=17750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=46, score=0.486, total=   1.1s\n",
      "[CV] max_iter=17750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=17750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=46, score=0.728, total=   0.5s\n",
      "[CV] max_iter=17750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=46, score=0.737, total=   1.2s\n",
      "[CV] max_iter=17750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=17750.0, C=46, score=0.709, total=   1.0s\n",
      "[CV] max_iter=20250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=46, score=0.486, total=   1.0s\n",
      "[CV] max_iter=20250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=20250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=46, score=0.728, total=   0.6s\n",
      "[CV] max_iter=20250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=46, score=0.737, total=   1.1s\n",
      "[CV] max_iter=20250.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=20250.0, C=46, score=0.709, total=   1.0s\n",
      "[CV] max_iter=22750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=46, score=0.486, total=   1.0s\n",
      "[CV] max_iter=22750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=46, score=0.589, total=   1.1s\n",
      "[CV] max_iter=22750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=46, score=0.728, total=   0.5s\n",
      "[CV] max_iter=22750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=46, score=0.737, total=   1.6s\n",
      "[CV] max_iter=22750.0, C=46 ..........................................\n",
      "[CV] .............. max_iter=22750.0, C=46, score=0.709, total=   1.1s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  6.3min finished\n",
      "/Users/borisrubel/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(), n_iter=100,\n",
       "                   param_distributions={'C': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46],\n",
       "                                        'max_iter': [250.0, 2750.0, 5250.0,\n",
       "                                                     7750.0, 10250.0, 12750.0,\n",
       "                                                     15250.0, 17750.0, 20250.0,\n",
       "                                                     22750.0]},\n",
       "                   random_state=1, verbose=3)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "\n",
    "print(\"Best Score using Random CV: \" + str(random_clf.best_score_))\n",
    "print(\"Parameters Used :\" + str(random_clf.best_params_))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Score using Random CV: 0.6504105090311987\n",
      "Parameters Used :{'max_iter': 250.0, 'C': 6}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "num_est = [x for x in range(1,20)]\n",
    "criteria = [\"gini\",\"entropy\"]\n",
    "j = 1\n",
    "trains_rf = []\n",
    "tests_rf = []\n",
    "for n in num_est:\n",
    "    for c in criteria:\n",
    "        RF = RandomForestClassifier(n_estimators = n, criterion = c,bootstrap='false')\n",
    "        RF.fit(X_train_scaled,train_labels)\n",
    "\n",
    "        print(\"-------------------\")\n",
    "        print(f\"iteration number: {j}\")\n",
    "        print(f\"training score : {RF.score(X_train_scaled,train_labels)}\")\n",
    "        print(f\"testing score : {RF.score(X_test_scaled,test_labels)}\")\n",
    "        print(f\"number of estimators: {n}, criteria: {c} \")\n",
    "        trains_rf.append(RF.score(X_train_scaled,train_labels))\n",
    "        tests_rf.append(RF.score(X_test_scaled,test_labels))\n",
    "        j = j+1 "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------\n",
      "iteration number: 1\n",
      "training score : 0.879064039408867\n",
      "testing score : 0.5172267120374309\n",
      "number of estimators: 1, criteria: gini \n",
      "-------------------\n",
      "iteration number: 2\n",
      "training score : 0.8847290640394089\n",
      "testing score : 0.5061675882603147\n",
      "number of estimators: 1, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 3\n",
      "training score : 0.877504105090312\n",
      "testing score : 0.5689068481497235\n",
      "number of estimators: 2, criteria: gini \n",
      "-------------------\n",
      "iteration number: 4\n",
      "training score : 0.8825944170771757\n",
      "testing score : 0.5572096980008507\n",
      "number of estimators: 2, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 5\n",
      "training score : 0.946551724137931\n",
      "testing score : 0.5008507018290089\n",
      "number of estimators: 3, criteria: gini \n",
      "-------------------\n",
      "iteration number: 6\n",
      "training score : 0.94376026272578\n",
      "testing score : 0.5521054870267971\n",
      "number of estimators: 3, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 7\n",
      "training score : 0.945320197044335\n",
      "testing score : 0.5603998298596342\n",
      "number of estimators: 4, criteria: gini \n",
      "-------------------\n",
      "iteration number: 8\n",
      "training score : 0.9507389162561576\n",
      "testing score : 0.5857082092726499\n",
      "number of estimators: 4, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 9\n",
      "training score : 0.9706896551724138\n",
      "testing score : 0.6507868991918333\n",
      "number of estimators: 5, criteria: gini \n",
      "-------------------\n",
      "iteration number: 10\n",
      "training score : 0.9710180623973728\n",
      "testing score : 0.5544449170565716\n",
      "number of estimators: 5, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 11\n",
      "training score : 0.972167487684729\n",
      "testing score : 0.5316886431305827\n",
      "number of estimators: 6, criteria: gini \n",
      "-------------------\n",
      "iteration number: 12\n",
      "training score : 0.9744663382594417\n",
      "testing score : 0.6271799234368354\n",
      "number of estimators: 6, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 13\n",
      "training score : 0.9842364532019704\n",
      "testing score : 0.5927264993619736\n",
      "number of estimators: 7, criteria: gini \n",
      "-------------------\n",
      "iteration number: 14\n",
      "training score : 0.984072249589491\n",
      "testing score : 0.5765631646108039\n",
      "number of estimators: 7, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 15\n",
      "training score : 0.9834975369458128\n",
      "testing score : 0.6290940025521055\n",
      "number of estimators: 8, criteria: gini \n",
      "-------------------\n",
      "iteration number: 16\n",
      "training score : 0.984072249589491\n",
      "testing score : 0.5393449595916632\n",
      "number of estimators: 8, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 17\n",
      "training score : 0.9917077175697865\n",
      "testing score : 0.5823054019566142\n",
      "number of estimators: 9, criteria: gini \n",
      "-------------------\n",
      "iteration number: 18\n",
      "training score : 0.9879310344827587\n",
      "testing score : 0.5716716290940026\n",
      "number of estimators: 9, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 19\n",
      "training score : 0.9908866995073892\n",
      "testing score : 0.6348362398979158\n",
      "number of estimators: 10, criteria: gini \n",
      "-------------------\n",
      "iteration number: 20\n",
      "training score : 0.9899014778325124\n",
      "testing score : 0.5831561037856231\n",
      "number of estimators: 10, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 21\n",
      "training score : 0.9929392446633826\n",
      "testing score : 0.6014461931093151\n",
      "number of estimators: 11, criteria: gini \n",
      "-------------------\n",
      "iteration number: 22\n",
      "training score : 0.9933497536945812\n",
      "testing score : 0.5701829008932369\n",
      "number of estimators: 11, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 23\n",
      "training score : 0.9922003284072249\n",
      "testing score : 0.6290940025521055\n",
      "number of estimators: 12, criteria: gini \n",
      "-------------------\n",
      "iteration number: 24\n",
      "training score : 0.9930213464696224\n",
      "testing score : 0.6467460655040408\n",
      "number of estimators: 12, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 25\n",
      "training score : 0.9957307060755337\n",
      "testing score : 0.5810293492131008\n",
      "number of estimators: 13, criteria: gini \n",
      "-------------------\n",
      "iteration number: 26\n",
      "training score : 0.9951559934318555\n",
      "testing score : 0.606763079540621\n",
      "number of estimators: 13, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 27\n",
      "training score : 0.9961412151067324\n",
      "testing score : 0.6105912377711612\n",
      "number of estimators: 14, criteria: gini \n",
      "-------------------\n",
      "iteration number: 28\n",
      "training score : 0.9941707717569787\n",
      "testing score : 0.6071884304551255\n",
      "number of estimators: 14, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 29\n",
      "training score : 0.9957307060755337\n",
      "testing score : 0.6180348787749894\n",
      "number of estimators: 15, criteria: gini \n",
      "-------------------\n",
      "iteration number: 30\n",
      "training score : 0.9970443349753695\n",
      "testing score : 0.6116546150574224\n",
      "number of estimators: 15, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 31\n",
      "training score : 0.99688013136289\n",
      "testing score : 0.615908124202467\n",
      "number of estimators: 16, criteria: gini \n",
      "-------------------\n",
      "iteration number: 32\n",
      "training score : 0.9967159277504105\n",
      "testing score : 0.6216503615482774\n",
      "number of estimators: 16, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 33\n",
      "training score : 0.9977832512315271\n",
      "testing score : 0.5963419821352616\n",
      "number of estimators: 17, criteria: gini \n",
      "-------------------\n",
      "iteration number: 34\n",
      "training score : 0.9973727422003285\n",
      "testing score : 0.5606125053168864\n",
      "number of estimators: 17, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 35\n",
      "training score : 0.997208538587849\n",
      "testing score : 0.6892811569544874\n",
      "number of estimators: 18, criteria: gini \n",
      "-------------------\n",
      "iteration number: 36\n",
      "training score : 0.997208538587849\n",
      "testing score : 0.6603572947681837\n",
      "number of estimators: 18, criteria: entropy \n",
      "-------------------\n",
      "iteration number: 37\n",
      "training score : 0.9976190476190476\n",
      "testing score : 0.5599744789451297\n",
      "number of estimators: 19, criteria: gini \n",
      "-------------------\n",
      "iteration number: 38\n",
      "training score : 0.9986863711001642\n",
      "testing score : 0.7048064653339005\n",
      "number of estimators: 19, criteria: entropy \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "x_vals = [x for x in range(len(trains_rf))]\n",
    "plt.plot(x_vals,trains_rf)\n",
    "plt.plot(x_vals,tests_rf)\n",
    "print(\"Training Data Max Score and Iteration Number: \")\n",
    "print(max(trains_rf),trains_rf.index(max(trains_rf))+1) \n",
    "print(\"Testing Data Max Score and Iteration Number: \")\n",
    "print(max(tests_rf),tests_rf.index(max(tests_rf))+1) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Data Max Score and Iteration Number: \n",
      "0.9986863711001642 38\n",
      "Testing Data Max Score and Iteration Number: \n",
      "0.7048064653339005 38\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Result Comparision\n",
    "Unscaled Logistic Regression: \\\n",
    "Best Scores during parameter tuning gave .704 for training and .58 for testing data. \\\n",
    "\\\n",
    "Unscaled Random Forest:\\\n",
    "Best Scores during parameter tuning gave .998 for training and .676 for testing data.\\\n",
    "\\\n",
    "Scaled Logistic Regression:\\\n",
    "Best Scores during parameter tuning gave .71 for training and .72 for testing data.\\\n",
    "\\\n",
    "Scaled Random Forest:\\\n",
    "Best Scores during parameter tuning gave .998 for training and .704 for testing data. Using Random CV recieved a score of .65, however this can change as it is a random  sample of all possible parameter selections. \n",
    "\n",
    "Logistic regression performed as expected, having recieved scores higher than that of the random forest before and after scaling. Afer scaling there was a drastic improvement in model performance in the logistic regression models, whereas the random forest models remained relatively the same. Even though logistic regression received significantly worse scores on the training data, it performed better on the testing data. The random forest model on the otherhand shows evidence of overfitting, with some parameter combinations yeilding scores of 1.0. As a result the testing scores were worse, but not significantly worse than those of logistic regression. \n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "interpreter": {
   "hash": "3b2f14ec1f892092573c23443df090b391e6e47fc55f5484814ef358ce94a7e6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}